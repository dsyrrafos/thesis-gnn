{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline Noisy Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "BfUaEY6tZhfr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceeu5__MIR2G",
        "outputId": "139550ba-d490-4cfc-b51b-895293a80a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lEzOrS5IWvf",
        "outputId": "ef7f04b0-b75d-4961-be63-e793a42c30bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "#os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0,nb_path)"
      ],
      "metadata": {
        "id": "UOphoV5doycA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc65f5dd-363e-4bf6-ff97-b3bae9a064e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --target=$nb_path torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install --target=$nb_path torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n",
        "!pip install --target=$nb_path torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kbQWTF12IYZF",
        "outputId": "ad52a3aa-59a6-49be-b359-327f93b9375c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=274491 sha256=ea6b31226b2d62ba3720ee1eb1a4477dcde8ee92c1e1969350aa8480f1640067\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-+.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.15.tar.gz (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl size=516860 sha256=0faffa795a131452f8e959e421a68e403398eb435560b37b6a34f88d060ad617\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/68/4d/1414be5c2c622bad35364e13213180797717b6d4b8923936dc\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.1.0.post1-py3-none-any.whl\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyparsing\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 44.2 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 43.0 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 49.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, urllib3, threadpoolctl, scipy, MarkupSafe, joblib, idna, charset-normalizer, certifi, tqdm, scikit-learn, requests, pyparsing, jinja2, torch-geometric\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
            "Successfully installed MarkupSafe-2.1.1 certifi-2022.6.15 charset-normalizer-2.1.1 idna-3.3 jinja2-3.1.2 joblib-1.1.0 numpy-1.21.6 pyparsing-3.0.9 requests-2.28.1 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0 torch-geometric-2.1.0.post1 tqdm-4.64.0 urllib3-1.26.12\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/threadpoolctl-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/idna-3.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/scipy-1.7.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/joblib-1.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/MarkupSafe-2.1.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/jinja2 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/pyparsing-3.0.9.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/Jinja2-3.1.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/scikit_learn-1.0.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/requests-2.28.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/numpy-1.21.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/markupsafe already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/pyparsing already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/torch_geometric already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/tqdm-4.64.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/certifi-2022.6.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
            "\u001b[33mWARNING: Target directory /content/notebooks/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0,nb_path)"
      ],
      "metadata": {
        "id": "Y6wBJ1Y6t7Pf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create baseline dataset"
      ],
      "metadata": {
        "id": "omfFpCxMJPEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset parameters"
      ],
      "metadata": {
        "id": "P8BPQ-CJ5BvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "\n",
        "num_total_nodes = 100\n",
        "num_labeled_nodes = 20\n",
        "num_unlabeled_nodes = num_total_nodes - num_labeled_nodes\n",
        "num_train_edges_per_class = int(num_labeled_nodes / num_classes)\n",
        "\n",
        "print('Total nodes:', num_total_nodes)\n",
        "print('Train nodes:', num_labeled_nodes)\n",
        "print('Test nodes:', num_unlabeled_nodes)\n",
        "print('Max number of train edges:', num_train_edges_per_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcxFY4D25Amp",
        "outputId": "f8e7bb9a-5a59-4a44-c259-8e821c6177f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total nodes: 100\n",
            "Train nodes: 20\n",
            "Test nodes: 80\n",
            "Max number of train edges: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = range(num_classes)\n",
        "\n",
        "labeled_nodes = list(range(num_labeled_nodes))\n",
        "train_nodes = labeled_nodes\n",
        "unlabled_nodes = list(range(num_labeled_nodes, num_total_nodes))\n",
        "test_nodes = unlabled_nodes\n",
        "\n",
        "print(train_nodes)\n",
        "print(test_nodes)"
      ],
      "metadata": {
        "id": "YQ6Dl4JQN1yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785682f6-68c0-4832-d170-3826955acbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create trainset"
      ],
      "metadata": {
        "id": "ytzemnMOqINT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create meaningful relation"
      ],
      "metadata": {
        "id": "VGJxI-Os1cOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "classes_list = []\n",
        "for i in range (num_classes):\n",
        "  nodes_list = []\n",
        "  for j in range (num_train_edges_per_class):\n",
        "    node_idx = randint(0, len(labeled_nodes)-1)\n",
        "    node = labeled_nodes[node_idx]\n",
        "    nodes_list.append(node)\n",
        "    labeled_nodes.remove(node)\n",
        "  classes_list.append(nodes_list)\n",
        "\n",
        "classes_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nENaq7hHmq4",
        "outputId": "bb68313c-8027-4a3d-eeaf-e902bf8e7003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 14, 1, 2, 11], [0, 13, 3, 8, 4], [18, 12, 19, 15, 9], [6, 17, 10, 7, 16]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "edge_list = []\n",
        "for node_list in classes_list:\n",
        "  edge_per_class_list = []\n",
        "  for idx, node in enumerate(node_list):\n",
        "    tail = choice([x for x in node_list if x != node])\n",
        "    if (tail,node) not in edge_per_class_list:\n",
        "      edge_per_class_list.append((node, tail))\n",
        "  edge_list.append(edge_per_class_list)\n",
        "\n",
        "edge_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7FaLHiHHhu",
        "outputId": "19223818-d13f-480e-fbf4-6aabb02260d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(5, 2), (14, 2), (1, 14), (11, 1)],\n",
              " [(0, 3), (13, 0), (3, 4), (8, 3), (4, 8)],\n",
              " [(18, 15), (12, 19), (19, 18), (15, 12), (9, 15)],\n",
              " [(6, 17), (17, 16), (10, 7), (7, 6), (16, 6)]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "edge_list = list(itertools.chain.from_iterable(edge_list))  "
      ],
      "metadata": {
        "id": "RiUmsDaNxnFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_nodes = list(range(num_labeled_nodes))\n",
        "train_nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHcrbzFWg_1T",
        "outputId": "db76b8c0-b4c5-4186-e66b-d1e55dc886c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_edges = edge_list \n",
        "training_edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANv7P9VihBx0",
        "outputId": "fc5cf9a9-1681-4266-d194-045a8af25270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 2),\n",
              " (14, 2),\n",
              " (1, 14),\n",
              " (11, 1),\n",
              " (0, 3),\n",
              " (13, 0),\n",
              " (3, 4),\n",
              " (8, 3),\n",
              " (4, 8),\n",
              " (18, 15),\n",
              " (12, 19),\n",
              " (19, 18),\n",
              " (15, 12),\n",
              " (9, 15),\n",
              " (6, 17),\n",
              " (17, 16),\n",
              " (10, 7),\n",
              " (7, 6),\n",
              " (16, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_edges = sorted(training_edges, key=lambda x: x[0])\n",
        "training_edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o03Pwozd4F2",
        "outputId": "554f68c8-6286-4687-fa6c-3353b63b0f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 3),\n",
              " (1, 14),\n",
              " (3, 4),\n",
              " (4, 8),\n",
              " (5, 2),\n",
              " (6, 17),\n",
              " (7, 6),\n",
              " (8, 3),\n",
              " (9, 15),\n",
              " (10, 7),\n",
              " (11, 1),\n",
              " (12, 19),\n",
              " (13, 0),\n",
              " (14, 2),\n",
              " (15, 12),\n",
              " (16, 6),\n",
              " (17, 16),\n",
              " (18, 15),\n",
              " (19, 18)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create noise relation"
      ],
      "metadata": {
        "id": "Zsm5DNVn3Huq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_edges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_0_vRTA3Ju7",
        "outputId": "c990810b-3c15-4294-bac5-42506544493f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsVUWGyn5cip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to create a noisy relation with similar number of edges as the meaningful relation."
      ],
      "metadata": {
        "id": "qehmlqMJ3UoF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORB-ZZCh3dIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create labels"
      ],
      "metadata": {
        "id": "omm-DcSSgCWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wXPHVpBgHAr",
        "outputId": "d81eef39-43d3-471b-e1fb-d7e4dc99e8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[17, 6, 18, 1, 12], [13, 10, 7, 15, 8], [0, 14, 2, 11, 19], [5, 4, 3, 9, 16]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "training_labels = np.zeros(num_labeled_nodes)\n",
        "\n",
        "for i, node_list in enumerate(classes_list):\n",
        "   for node in node_list:\n",
        "     training_labels[node] = i\n",
        "\n",
        "training_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv8fXvJ1hltv",
        "outputId": "1f1f3b97-bd64-46bc-a593-48334b71ff8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 0., 2., 3., 3., 3., 0., 1., 1., 3., 1., 2., 0., 1., 2., 1., 3.,\n",
              "       0., 0., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create initial node embeddings"
      ],
      "metadata": {
        "id": "DXGl1C5udTht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We choose zero-embeddings as initial ones to make sure no information is provided by them and that all information should be extracted by the relations"
      ],
      "metadata": {
        "id": "hWiZJKrjdo9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb_size = 1"
      ],
      "metadata": {
        "id": "FpBDvVbzlKkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_embs = np.zeros((num_total_nodes, emb_size))"
      ],
      "metadata": {
        "id": "7dIAsb2cdouy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VtLCyuMhCob",
        "outputId": "8669b3da-f15a-4a85-fa90-1367d3c8d541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset class"
      ],
      "metadata": {
        "id": "lGCt-5ar2dSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, download_url"
      ],
      "metadata": {
        "id": "eX9B-RPw2akM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "26f13ec3-7260-4cf8-e24c-f1f180759cd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5a8560001c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseNoiseDataset(InMemoryDataset):\n"
      ],
      "metadata": {
        "id": "LXYHe50tiiH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store dataset"
      ],
      "metadata": {
        "id": "e2Qh5d8dZsvi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxahmpZiZu8v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}